Fill out this <strong>[form](https://www.mathworks.com/academia/student-challenge/mathworks-excellence-in-innovation-signup.html?tfa_1=Face%20Detection%20and%20Human%20Tracking%20Robot&tfa_2=214)</strong> to **register** your intent to complete this project.

Fill out this <strong>[form](https://www.mathworks.com/academia/student-challenge/mathworks-excellence-in-innovation-submission-form.html?tfa_1=Face%20Detection%20and%20Human%20Tracking%20Robot&tfa_2=214)</strong> to **submit** your solution to this project and qualify for the rewards.

<table>
<td><img src="https://gist.githubusercontent.com/robertogl/e0115dc303472a9cfd52bbbc8edb7665/raw/HumanTrackingRobot.png"  width=400 /></td>
<td><p><h1>Face Detection and Human Tracking Robot</h1></p>
<p> Design and implement a real time autonomous human tracking robot using low-cost hardware.</p>
</table>

## Motivation

Human-robot interaction is important in many computer vision applications, including activity recognition, automotive safety, smart home security applications and surveillance. 
The task of a robot is to be a useful assistant to help people with their work. The robot must be able to interact with humans and to communicate well. For this condition, human face tracking system becomes the main requirement for vision system in this type of robots. Face detection can increase the Robot's ability for Human-Robot Interaction. Detecting and tracking human automatically with a sensor or an algorithm is a challenging problem due to the wide variety of positions, complexity of the system, and in the end a detailed optimization problem. This process involves extracting, selecting the best features and then tracking. In this project, you will explore, design and test to finding the optimal algorithm for face detection and tracking.


## Project Description

Design and implement a low cost, user friendly, and real time autonomous human tracking robot using Android device and Deep Learning technology. The face detection is done by the Android device while the real-time control is done by either Arduino or Raspberry Pi based controller. 
The face detection algorithm will be designed using [Computer Vision Toolbox™](https://www.mathworks.com/products/computer-vision.html) and [Deep Learning Toolbox™](https://www.mathworks.com/products/deep-learning.html).  Work with the Simulink based Hardware support packages to deploy this algorithm on to hardware. An Android device will be used to run the computation intensive face detection algorithm which will then pass the information to Arduino or Raspberry Pi to control the movements of Robot.  Finally, a workflow that demonstrates Deep Learning based Face detection and tracking will be developed.

Suggested steps
1.	Develop an AI based face detection and tracking application for an Android device using the Simulink support package for Android. Use the below examples as a reference for getting started with face detection using the Android device
a.	[Detect and Track Face on Android Device](https://www.mathworks.com/help/supportpkg/android/ref/detect-and-track-face-on-an-android-device.html)
2.	Design a robot based on Arduino or Raspberry Pi using the Simulink support packages for Arduino or Raspberry Pi. Use the below examples as a reference for getting started with creating a robot using Arduino/Raspberry Pi hardware
a.	[Control a Raspberry Pi powered robot with MATLAB and Simulink](https://www.mathworks.com/matlabcentral/fileexchange/47376-control-a-raspberry-pi-powered-robot-with-matlab-and-simulink)
3.	The Android application for face detection and recognition should be able to communicate the position of the human with respect to the robot on which it is mounted. Use the below examples as a reference for getting started with creating a robot using Arduino/Raspberry Pi hardware
a.	[Control Raspberry Pi from your Android Device using Simulink](https:\www.mathworks.com\matlabcentral\fileexchange\59204-control-raspberry-pi-from-your-android-device-using-simulink)
4.	After getting the coordinates of the human, the robot should move towards him/her and stop at a pre-defined distance.  
5.	The entire system should now track and move towards the human as an when they change their location. 


## Background Material

- [Computer Vision Toolbox](https://www.mathworks.com/products/computer-vision.html)
- [Deep Learning Toolbox](https://www.mathworks.com/products/deep-learning.html)
- [Deep Learning Toolbox Examples](https://www.mathworks.com/help/deeplearning/examples.html)
- [Simulink Support Package for Android Devices](https://www.mathworks.com/help/supportpkg/android/)
- [Simulink Support Package for Arduino Hardware](https://www.mathworks.com/hardware-support/arduino-simulink.html)
- [Simulink Support Package for Raspberry Pi Hardware](https://www.mathworks.com/hardware-support/raspberry-pi-simulink.html)


## Impact

Leverage mobile technology and deep learning to advance face detection algorithms for impacting human safety and security.

## Expertise Gained 

Artificial Intelligence, Computer Vision, Robotics, Deep Learning, Embedded AI, Human-Robot Interaction, Mobile Robots, Modeling and Simulation, Machine Learning, Low-cost Hardware, Image Processing, Control


## Project Difficulty

Bachelor

## Project Discussion

[Dedicated discussion forum](https://github.com/mathworks/MathWorks-Excellence-in-Innovation/discussions/45) to ask/answer questions, comment, or share your ideas for solutions for this project.

## Proposed By

[dryouwu](https://github.com/dryouwu)

## Project Number

214
